{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GvPvqUPMhqo5"
      },
      "source": [
        "### Install dependencies"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers datasets torch\n",
        "!pip install rouge_score\n",
        "!pip install evaluate"
      ],
      "metadata": {
        "id": "dMjePfBakYom"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rgvFKiznh3JZ"
      },
      "source": [
        "### Load dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "\n",
        "dataset = load_dataset(\"cnn_dailymail\", \"3.0.0\")\n",
        "\n",
        "dataset[\"train\"][0], dataset[\"validation\"][0]"
      ],
      "metadata": {
        "id": "Vy6twZszkgyf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sg6rOsp8iG8w"
      },
      "source": [
        "### Preprocess data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ulr0Wq1KiXIo"
      },
      "outputs": [],
      "source": [
        "train_subset = dataset[\"train\"].select(range(1000))\n",
        "valid_subset = dataset[\"validation\"].select(range(100))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import T5Tokenizer\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def tokenize_function(examples):\n",
        "\n",
        "    model_inputs = tokenizer(examples['article'], padding=\"max_length\", truncation=True, max_length=512)\n",
        "\n",
        "    with tokenizer.as_target_tokenizer():\n",
        "        labels = tokenizer(examples['highlights'], padding=\"max_length\", truncation=True, max_length=150)\n",
        "\n",
        "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
        "    return model_inputs\n",
        "\n",
        "\n",
        "tokenized_train_dataset= train_subset.map(tokenize_function, batched=True)\n",
        "tokenized_validation_dataset= valid_subset.map(tokenize_function, batched=True)"
      ],
      "metadata": {
        "id": "9sWVc7EHkpGF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tG2Ayw2djS5D"
      },
      "source": [
        "### Load model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zbLMovtfivTR"
      },
      "outputs": [],
      "source": [
        "from transformers import T5ForConditionalGeneration\n",
        "\n",
        "\n",
        "model = T5ForConditionalGeneration.from_pretrained(\"t5-small\")\n",
        "\n",
        "\n",
        "for param in model.encoder.block[:5]:\n",
        "    for p in param.parameters():\n",
        "        p.requires_grad = False\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OTUAzJZyjeTq"
      },
      "outputs": [],
      "source": [
        "from transformers import Trainer, TrainingArguments\n",
        "\n",
        "\n",
        "model.config.dropout_rate = 0.3\n",
        "\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    evaluation_strategy=\"steps\",\n",
        "    eval_steps=2000,\n",
        "    save_steps=2000,\n",
        "    learning_rate=5e-5,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.01,\n",
        "    save_total_limit=2,\n",
        "    gradient_accumulation_steps=2,\n",
        "    fp16=True,\n",
        "    logging_dir=\"./logs\",\n",
        "    logging_steps=100,\n",
        "    load_best_model_at_end=True,\n",
        "    lr_scheduler_type=\"linear\",\n",
        "    warmup_steps=1000,\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_train_dataset,\n",
        "    eval_dataset=tokenized_validation_dataset,\n",
        "    tokenizer=tokenizer\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PCfiVQwdlFz2"
      },
      "source": [
        "### Train the model on 1,000 examples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8tsssLaCkluo"
      },
      "outputs": [],
      "source": [
        "trainer.train()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z1286SpolvdQ"
      },
      "source": [
        "### Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zsKdoPx0lEQy"
      },
      "outputs": [],
      "source": [
        "results = trainer.evaluate()\n",
        "\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-GogH60x59H2"
      },
      "source": [
        "### Predict results on test data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cuhBakVXM8Yj"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "device_0 = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model.to(device_0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MQRrcPJx5wYe"
      },
      "outputs": [],
      "source": [
        "import evaluate\n",
        "\n",
        "\n",
        "rouge = evaluate.load(\"rouge\")\n",
        "\n",
        "def evaluate_model_on_test(model, dataset, tokenizer):\n",
        "    predictions = []\n",
        "    references = []\n",
        "\n",
        "    device = model.device\n",
        "\n",
        "    for example in dataset:\n",
        "        article = example[\"article\"]\n",
        "        reference = example[\"highlights\"]\n",
        "\n",
        "        inputs = tokenizer(article, return_tensors=\"pt\", padding=\"max_length\", truncation=True, max_length=512)\n",
        "        inputs = {key: value.to(device) for key, value in inputs.items()}\n",
        "\n",
        "        summary_ids = model.generate(inputs[\"input_ids\"], max_length=150, num_beams=4, early_stopping=True)\n",
        "        prediction = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "\n",
        "        predictions.append(prediction)\n",
        "        references.append(reference)\n",
        "\n",
        "    results = rouge.compute(predictions=predictions, references=references)\n",
        "    return results\n",
        "\n",
        "test_results = evaluate_model_on_test(model, dataset[\"test\"].select(range(100)), tokenizer)\n",
        "\n",
        "for key, value in test_results.items():\n",
        "    print(f\"{key}: {value}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hmLCVgeQmLso"
      },
      "outputs": [],
      "source": [
        "from transformers import T5ForConditionalGeneration\n",
        "\n",
        "model_untrained = T5ForConditionalGeneration.from_pretrained(\"t5-small\")\n",
        "\n",
        "\n",
        "article = dataset[\"validation\"][0][\"article\"]\n",
        "\n",
        "def generate_summary(model, text):\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", padding=\"max_length\", truncation=True, max_length=512)\n",
        "\n",
        "    inputs = inputs.to(model.device)\n",
        "\n",
        "    summary_ids = model.generate(inputs[\"input_ids\"], max_length=150, num_beams=4, early_stopping=True)\n",
        "    return tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "\n",
        "summary_model = generate_summary(model, article)\n",
        "\n",
        "summary_model_untrained = generate_summary(model_untrained, article)\n",
        "\n",
        "print(\"Untrained model Summary:\")\n",
        "print(summary_model_untrained)\n",
        "print(\"\\nTrained model Summary:\")\n",
        "print(summary_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train model on 100,000 examples"
      ],
      "metadata": {
        "id": "iFR_eG6cBXwm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Select data"
      ],
      "metadata": {
        "id": "uTg8fVuKCgUD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-qP2wePbFQ8V"
      },
      "outputs": [],
      "source": [
        "train_subset_2 = dataset[\"train\"].select(range(100000))\n",
        "valid_subset_2 = dataset[\"validation\"].select(range(10000))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import T5Tokenizer\n",
        "\n",
        "tokenizer = T5Tokenizer.from_pretrained(\"t5-small\")\n",
        "\n",
        "def tokenize_function(examples):\n",
        "\n",
        "    model_inputs = tokenizer(examples['article'], padding=\"max_length\", truncation=True, max_length=512)\n",
        "\n",
        "    with tokenizer.as_target_tokenizer():\n",
        "        labels = tokenizer(examples['highlights'], padding=\"max_length\", truncation=True, max_length=150)\n",
        "\n",
        "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
        "    return model_inputs\n",
        "\n",
        "\n",
        "tokenized_train_dataset_2= train_subset_2.map(tokenize_function, batched=True)\n",
        "tokenized_validation_dataset_2= valid_subset_2.map(tokenize_function, batched=True)\n"
      ],
      "metadata": {
        "id": "rfv-adsNCqOi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load model"
      ],
      "metadata": {
        "id": "p7BmkZlnKpBP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import T5ForConditionalGeneration\n",
        "\n",
        "model_2 = T5ForConditionalGeneration.from_pretrained(\"t5-small\")\n",
        "\n",
        "for param in model_2.encoder.block[:5]:\n",
        "    for p in param.parameters():\n",
        "        p.requires_grad = False"
      ],
      "metadata": {
        "id": "PI-1o79EKx5Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Trainer, TrainingArguments\n",
        "\n",
        "model_2.config.dropout_rate = 0.3\n",
        "\n",
        "training_args_2 = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    evaluation_strategy=\"steps\",\n",
        "    eval_steps=2000,\n",
        "    save_steps=2000,\n",
        "    learning_rate=5e-5,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.01,\n",
        "    save_total_limit=2,\n",
        "    gradient_accumulation_steps=2,\n",
        "    fp16=True,\n",
        "    logging_dir=\"./logs\",\n",
        "    logging_steps=100,\n",
        "    load_best_model_at_end=True,\n",
        "    lr_scheduler_type=\"linear\",\n",
        "    warmup_steps=1000,\n",
        ")\n",
        "\n",
        "trainer_2 = Trainer(\n",
        "    model=model_2,\n",
        "    args=training_args_2,\n",
        "    train_dataset=tokenized_train_dataset_2,\n",
        "    eval_dataset=tokenized_validation_dataset_2,\n",
        "    tokenizer=tokenizer\n",
        ")\n"
      ],
      "metadata": {
        "id": "TvzexFX3K1bZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train model"
      ],
      "metadata": {
        "id": "F7oJa0hnK3Zx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer_2.train()"
      ],
      "metadata": {
        "id": "sYHG-aG3LWgp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluate"
      ],
      "metadata": {
        "id": "F6BWk9fELqN9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results = trainer_2.evaluate()\n",
        "\n",
        "print(results)"
      ],
      "metadata": {
        "id": "1GwNqsX1Lc_C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check performance"
      ],
      "metadata": {
        "id": "4YLf0yw9PrZh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "device_0 = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model_2.to(device_0)"
      ],
      "metadata": {
        "id": "Ymt_tzIYLc2b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import evaluate\n",
        "\n",
        "rouge = evaluate.load(\"rouge\")\n",
        "\n",
        "def evaluate_model_on_test(model, dataset, tokenizer):\n",
        "    predictions = []\n",
        "    references = []\n",
        "\n",
        "    device = model.device\n",
        "\n",
        "    for example in dataset:\n",
        "        article = example[\"article\"]\n",
        "\n",
        "        reference = example[\"highlights\"]\n",
        "\n",
        "        inputs = tokenizer(article, return_tensors=\"pt\", padding=\"max_length\", truncation=True, max_length=512)\n",
        "        inputs = {key: value.to(device) for key, value in inputs.items()}\n",
        "\n",
        "        summary_ids = model.generate(inputs[\"input_ids\"], max_length=150, num_beams=4, early_stopping=True)\n",
        "        prediction = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "\n",
        "        predictions.append(prediction)\n",
        "        references.append(reference)\n",
        "\n",
        "    results = rouge.compute(predictions=predictions, references=references)\n",
        "    return results\n",
        "\n",
        "test_results = evaluate_model_on_test(model_2, dataset[\"test\"].select(range(100)), tokenizer)\n",
        "\n",
        "for key, value in test_results.items():\n",
        "    print(f\"{key}: {value}\")"
      ],
      "metadata": {
        "id": "rcW2WPYyLcof"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model performance comparison"
      ],
      "metadata": {
        "id": "OlfmHkiASVNJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_summary(text):\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", padding=\"max_length\", truncation=True, max_length=512)\n",
        "\n",
        "    for k, v in inputs.items():\n",
        "        inputs[k] = v.to(model_2.device)\n",
        "\n",
        "    summary_ids = model_2.generate(inputs[\"input_ids\"], max_length=350, num_beams=8, early_stopping=True)\n",
        "    return tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "\n",
        "\n",
        "model_untrained = T5ForConditionalGeneration.from_pretrained(\"t5-small\")\n",
        "\n",
        "article = dataset[\"validation\"][0][\"article\"]\n",
        "\n",
        "summary_model_untrained = generate_summary(model_untrained, article)\n",
        "summary_model_trained_1000 = generate_summary(model_2, article)\n",
        "summary_model_trained_100000 = generate_summary(model_2, article)\n",
        "\n",
        "print(\"Untrained model Summary:\")\n",
        "print(summary_model_untrained)\n",
        "print(\"\\nTrained model on 1,000 examples:\")\n",
        "print(summary_model_trained_1000)\n",
        "print(\"\\nTrained model on 100,000 examples:\")\n",
        "print(summary_model_trained_100000)"
      ],
      "metadata": {
        "id": "ITe1Z5frP1HO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Save model"
      ],
      "metadata": {
        "id": "tM8SfYrjhe1U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "output_dir = \"./t5_finetuned_model_2\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "model_2.save_pretrained(output_dir)\n",
        "\n",
        "tokenizer.save_pretrained(output_dir)"
      ],
      "metadata": {
        "id": "lVHCJC0vLdHg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "shutil.make_archive(\"./t5_finetuned_model_2\", \"zip\", output_dir)"
      ],
      "metadata": {
        "id": "GNweWwNAhkaS"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}